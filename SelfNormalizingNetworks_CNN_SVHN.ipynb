{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU vs SELU networks on the SVHN data set\n",
    "\n",
    "Adapted from SNNs bioinf-jku [SNNs bioinf-jku](https://github.com/bioinf-jku/SNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fetch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "last_percent_reported = None\n",
    "\n",
    "def get_data_set(name=\"train\"):\n",
    "    x = None\n",
    "    y = None\n",
    "    \n",
    "    if name is \"train\":\n",
    "        train_matfile = maybe_download('./data_set/train_32x32.mat')\n",
    "        train_data = scipy.io.loadmat('./data_set/train_32x32.mat', variable_names='X').get('X')\n",
    "        train_labels = scipy.io.loadmat('./data_set/train_32x32.mat', variable_names='y').get('y')\n",
    "        \n",
    "        x = train_data\n",
    "        y = train_labels\n",
    "        y[y == 10] = 0      \n",
    "        \n",
    "        y = dense_to_one_hot(y)\n",
    "        \n",
    "        x_mean_train = x.mean()\n",
    "        x_sdev_train = x.std()\n",
    "        x_var_train = x.var()\n",
    "        \n",
    "        x = (x - x_mean_train) / x_sdev_train\n",
    "        x = x.reshape(32*32*3, 73257)\n",
    "        x = np.transpose(x)\n",
    "        \n",
    "    if name is \"test\":\n",
    "        test_matfile = maybe_download('./data_set/test_32x32.mat')\n",
    "        test_data = scipy.io.loadmat('./data_set/test_32x32.mat', variable_names='X').get('X')\n",
    "        test_labels = scipy.io.loadmat('./data_set/test_32x32.mat', variable_names='y').get('y')\n",
    "        \n",
    "        xt = test_data\n",
    "        yt = test_labels\n",
    "        yt[yt == 10] = 0\n",
    "        \n",
    "        y = dense_to_one_hot(yt)\n",
    "        \n",
    "        x_mean_test = xt.mean()\n",
    "        x_sdev_test = xt.std()\n",
    "        x_var_test = xt.var()\n",
    "        \n",
    "        x = (xt - x_mean_test) / x_sdev_test\n",
    "        x = x.reshape(32*32*3, 26032)\n",
    "        x = np.transpose(x)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "\n",
    "    return labels_one_hot\n",
    "\n",
    "def _print_download_progress(count, block_size, total_size):\n",
    "    pct_complete = float(count * block_size) / total_size\n",
    "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def maybe_download(filename, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if force or not os.path.exists(filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, filename, reporthook=_print_download_progress)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(filename)\n",
    "  return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "def selu(x, name=\"selu\"):\n",
    "    \"\"\" When using SELUs you have to keep the following in mind:\n",
    "    # (1) scale inputs to zero mean and unit variance\n",
    "    # (2) use SELUs\n",
    "    # (3) initialize weights with stddev sqrt(1/n)\n",
    "    # (4) use SELU dropout\n",
    "    \"\"\"\n",
    "    with ops.name_scope(name) as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale * tf.where(x >= 0.0, x, alpha * tf.nn.elu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpers to build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, activation, stddev, wd=None):    \n",
    "    # Determine number of input features from shape\n",
    "    f_in = np.prod(shape[:-1]) if len(shape) == 4 else shape[0]\n",
    "    # Determine number of ouput features from shape\n",
    "    f_out = shape[-1]\n",
    "    \n",
    "    # Calculate sdev for initialization according to activation function\n",
    "    if activation == selu:\n",
    "        sdev = sqrt(1 / f_in)\n",
    "#         sdev = sqrt(2 / f_in)# He Initialization\n",
    "#         sdev = sqrt(2 / (f_in+f_out)) #Xavier Initialization\n",
    "    elif activation == tf.nn.relu:\n",
    "#         sdev = sqrt(1 / f_in)\n",
    "        sdev = sqrt(2 / f_in)# He Initialization\n",
    "#         sdev = sqrt(2 / (f_in+f_out)) #Xavier Initialization\n",
    "    elif activation == tf.nn.elu:\n",
    "        sdev = sqrt(1.5505188080679277 / f_in)\n",
    "    else:\n",
    "        sdev = stddev\n",
    "    \n",
    "    var = tf.get_variable(name=name, shape=shape,\n",
    "                          initializer=tf.truncated_normal_initializer(stddev=sdev, dtype=tf.float32))\n",
    "    \n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def conv2d(scope_name, input, activation, ksize, f_in, f_out, bias_init=0.0, stddev=5e-2):\n",
    "    with tf.variable_scope(scope_name) as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[ksize, ksize, f_in, f_out], activation=activation,\n",
    "                                             stddev=stddev)\n",
    "        conv = tf.nn.conv2d(input, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.get_variable('biases', [f_out], initializer=tf.constant_initializer(bias_init), dtype=tf.float32)\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        return activation(pre_activation, name=scope.name)\n",
    "\n",
    "\n",
    "def fc(scope_name, input, activation, n_in, n_out, stddev=0.04, bias_init=0.0, weight_decay=None):\n",
    "    with tf.variable_scope(scope_name) as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[n_in, n_out], activation=activation, stddev=stddev,\n",
    "                                              wd=weight_decay)\n",
    "        biases = tf.get_variable(name='biases', shape=[n_out], initializer=tf.constant_initializer(bias_init),\n",
    "                                 dtype=tf.float32)\n",
    "        return activation(tf.matmul(input, weights) + biases, name=scope.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model with a specified activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(activation):\n",
    "    _IMAGE_SIZE = 32\n",
    "    _IMAGE_CHANNELS = 3\n",
    "    _NUM_CLASSES = 10\n",
    "    _RESHAPE_SIZE = 4 * 4 * 128\n",
    "    \n",
    "    # set activation function\n",
    "    act = selu if activation == \"selu\" else tf.nn.elu if activation == \"elu\" else tf.nn.relu\n",
    "    \n",
    "    with tf.variable_scope(activation):\n",
    "        # input\n",
    "        with tf.name_scope('data'):\n",
    "            x = tf.placeholder(tf.float32, shape=[None, _IMAGE_SIZE * _IMAGE_SIZE * _IMAGE_CHANNELS], name='Input')\n",
    "            y = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='Output')\n",
    "            x_image = tf.reshape(x, [-1, _IMAGE_SIZE, _IMAGE_SIZE, _IMAGE_CHANNELS], name='images')\n",
    "        \n",
    "        # Conv 1\n",
    "        conv1 = conv2d(\"conv1\", input=x_image, activation=act, ksize=5, f_in=3, f_out=64)\n",
    "        pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "        \n",
    "        # Conv 2\n",
    "        conv2 = conv2d(\"conv2\", input=pool1, activation=act, ksize=5, f_in=64, f_out=64, bias_init=0.1)\n",
    "        pool2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "        \n",
    "        # Conv 3-5\n",
    "        conv3 = conv2d(\"conv3\", input=pool2, activation=act, ksize=3, f_in=64, f_out=128)\n",
    "        conv4 = conv2d(\"conv4\", input=conv3, activation=act, ksize=3, f_in=128, f_out=128)\n",
    "        conv5 = conv2d(\"conv5\", input=conv4, activation=act, ksize=3, f_in=128, f_out=128)\n",
    "        \n",
    "        # Pool\n",
    "        pool3 = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool3')\n",
    "        \n",
    "        # Reshape\n",
    "        reshape = tf.reshape(pool3, [-1, _RESHAPE_SIZE])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        \n",
    "        # Fully Connected L2 Penalty\n",
    "        fc1 = fc('fully_connected1', input=reshape, activation=act, n_in=dim, n_out=384, stddev=0.04, bias_init=0.1,\n",
    "                 weight_decay=0.004)\n",
    "        fc2 = fc('fully_connected2', input=fc1, activation=act, n_in=384, n_out=192, stddev=0.04, bias_init=0.1,\n",
    "                 weight_decay=0.004)\n",
    "\n",
    "        # Fully Connected Dropout\n",
    "        #   fc1 = fc('fully_connected1', input=reshape, activation=act, n_in=dim, n_out=384, stddev=0.04, bias_init=0.1)\n",
    "        \n",
    "        #   keep_prob = tf.placeholder(tf.float32)\n",
    "        #   fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "        #   fc2 = fc('fully_connected2', input=fc1_drop, activation=act, n_in=384, n_out=192, stddev=0.04, bias_init=0.1)\n",
    "        #   fc2_drop = tf.nn.dropout(fc2, keep_prob)\n",
    "        \n",
    "        # Softmax\n",
    "        with tf.variable_scope('output') as scope:\n",
    "            #     Uncomment when using L2\n",
    "            weights = _variable_with_weight_decay('weights', [192, _NUM_CLASSES], stddev=1 / 192.0,\n",
    "                                                  activation=activation,\n",
    "                                                  wd=0.0)\n",
    "            #   Uncomment when using dropout\n",
    "            #   weights = _variable_with_weight_decay('weights', [192, _NUM_CLASSES], stddev=1 / 192.0,\n",
    "            #                                        activation=activation)\n",
    "            biases = tf.get_variable(name='biases', shape=[_NUM_CLASSES], initializer=tf.constant_initializer(0.0),\n",
    "                                     dtype=tf.float32)\n",
    "            softmax_linear = tf.add(tf.matmul(fc2, weights), biases, name=scope.name)\n",
    "            \n",
    "            # output\n",
    "            y_pred_cls = tf.argmax(softmax_linear, dimension=1)\n",
    "        \n",
    "        # Define Loss and Optimizer\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=softmax_linear, labels=y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "        # optimizer = tf.train.MomentumOptimizer(learning_rate=1e-4, momentum=0.9).minimize(loss)\n",
    "        \n",
    "        correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, dimension=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        # tf.summary.scalar(\"Accuracy/train\", accuracy)\n",
    "\n",
    "    #     Uncomment when using L2\n",
    "    return {\"x\": x, \"y\": y, \"output\": y_pred_cls, \"loss\": loss, \"accuracy\": accuracy, \"optimizer\": optimizer, \n",
    "            \"name\": activation}\n",
    "\n",
    "    #     Uncomment when using dropout\n",
    "#     return {\"x\": x, \"y\": y, \"output\": y_pred_cls, \"loss\": loss, \"accuracy\": accuracy, \"optimizer\": optimizer, \n",
    "#             \"name\": activation, \"keep_prob\": keep_prob}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_test(test_x, test_y, models):\n",
    "    \"\"\"\n",
    "        Make prediction for all images in test_x\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    predicted_class = {\"selu\": np.zeros(shape=len(test_x), dtype=np.int), \n",
    "                       #\"elu\": np.zeros(shape=len(test_x), dtype=np.int), \n",
    "                       \"relu\":np.zeros(shape=len(test_x), dtype=np.int)}\n",
    "    while i < len(test_x):\n",
    "        j = min(i + _BATCH_SIZE, len(test_x))\n",
    "        batch_xs = test_x[i:j, :]\n",
    "        batch_ys = test_y[i:j, :]\n",
    "        for name, model in models.items():\n",
    "            predicted_class[name][i:j] = sess.run(model[\"output\"], feed_dict={\n",
    "#                 model['x']: batch_xs, model['y']: batch_ys, model['keep_prob']: 1.0})\n",
    "                model['x']: batch_xs, model['y']: batch_ys})\n",
    "        i = j\n",
    "    \n",
    "    accuracy = {\"selu\": 0, \"relu\": 0}\n",
    "    for name, model in models.items():\n",
    "        correct = (np.argmax(test_y, axis=1) == predicted_class[name])        \n",
    "        accuracy[name] = correct.mean() * 100        \n",
    "    \n",
    "    print(\"Accuracy on Test-Set (SELU/RELU): {0:.2f}% | {1:.2f}% |\".format(\n",
    "        accuracy[\"selu\"], accuracy[\"relu\"]))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_metric(title, ylabel, metric):\n",
    "    # Training Accuracy\n",
    "    plt.figure()    \n",
    "    plt.title(title, size=\"xx-large\")\n",
    "    plt.ylabel(ylabel, size=\"x-large\")    \n",
    "    plt.tick_params(axis=\"x\", bottom=\"off\", labelbottom=\"off\")\n",
    "    \n",
    "    # select manually for consistent colors\n",
    "    plt.plot(metric[\"selu\"], label=\"SELU\", linewidth=2)\n",
    "    #plt.plot(metric[\"elu\"], label=\"ELU\", linewidth=2)\n",
    "    plt.plot(metric[\"relu\"], label=\"RELU\", linewidth=2)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot(train_loss, train_accuracy, test_accuracy):    \n",
    "    # Training Loss\n",
    "    plot_metric(\"Training Loss\", \"Loss\", train_loss)\n",
    "    \n",
    "    # Training Accuracy\n",
    "    plot_metric(\"Training Accuracy\", \"Accuracy\", train_accuracy)\n",
    "    \n",
    "    # Test Accuracy\n",
    "    plot_metric(\"Test Accuracy\", \"Accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(session, num_epoch, train_x, train_y, test_x, test_y, models):\n",
    "    \"\"\"\n",
    "        Train CNN\n",
    "    \"\"\"    \n",
    "    train_loss = {\"selu\": [], \"relu\": []}\n",
    "    train_accuracy = {\"selu\": [], \"relu\": []}    \n",
    "    test_accuracy = {\"selu\": [], \"relu\": []}\n",
    "    \n",
    "    # start training\n",
    "    print(time.localtime())\n",
    "    for epoch in range(num_epoch):\n",
    "        total_batch = int(train_x.shape[0]/_BATCH_SIZE)\n",
    "        print(\"Epoch: \", epoch) \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            randidx = np.random.randint(len(train_x), size=_BATCH_SIZE)\n",
    "            batch_xs = train_x[randidx]\n",
    "            batch_ys = train_y[randidx]\n",
    "\n",
    "            optimizers = []\n",
    "            feed_dict = {}\n",
    "            for name, model in models.items():\n",
    "                optimizers.append(model[\"optimizer\"])\n",
    "#                 feed_dict.update({model[\"x\"]: batch_xs, model[\"y\"]: batch_ys, model[\"keep_prob\"]: 0.5})\n",
    "                feed_dict.update({model[\"x\"]: batch_xs, model[\"y\"]: batch_ys})\n",
    "\n",
    "            # train\n",
    "            session.run( optimizers, feed_dict=feed_dict)\n",
    "\n",
    "            # print training loss\n",
    "            if (i % 10 == 0) :\n",
    "                l_selu, l_relu, acc_selu, acc_relu = session.run(\n",
    "                    [models['selu']['loss'],  models['relu']['loss'], \n",
    "                     models['selu']['accuracy'], models['relu']['accuracy']],\n",
    "                    feed_dict=feed_dict)\n",
    "\n",
    "                msg = \"Minibatch: {0:>6}, \" \\\n",
    "                      \"accuracy (SELU/RELU): {1:>6.1%} | {2:>6.1%} |, \" \\\n",
    "                      \"loss (SELU/RELU): {3:.2f} | {4:.2f} |\"\n",
    "                print(msg.format(i, acc_selu, acc_relu, l_selu, l_relu))            \n",
    "\n",
    "                # collect metrics for plots                            \n",
    "                train_loss[\"selu\"].append(l_selu)\n",
    "#                 train_loss[\"elu\"].append(l_elu)\n",
    "                train_loss[\"relu\"].append(l_relu)\n",
    "                train_accuracy[\"selu\"].append(acc_selu)\n",
    "#                 train_accuracy[\"elu\"].append(acc_elu)\n",
    "                train_accuracy[\"relu\"].append(acc_relu)\n",
    "\n",
    "        acc = predict_test(test_x, test_y, models)                \n",
    "        test_accuracy[\"selu\"].append(acc[\"selu\"])\n",
    "#         test_accuracy[\"elu\"].append(acc[\"elu\"])\n",
    "        test_accuracy[\"relu\"].append(acc[\"relu\"])\n",
    "        saver.save(session, save_path=_SAVE_PATH + \"/checkpoint\", global_step=epoch)\n",
    "        print(\"Saved checkpoint.\")\n",
    "        \n",
    "    print(time.localtime())\n",
    "    return train_loss, train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_IMG_SIZE = 32\n",
    "_NUM_CHANNELS = 3\n",
    "# _BATCH_SIZE = 128\n",
    "_BATCH_SIZE = 500\n",
    "_CLASS_SIZE = 10\n",
    "# _ITERATION = 10000\n",
    "_EPOCH = 50\n",
    "_SAVE_PATH = \"./checkpoints/svhn-he\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "if not os.path.exists(_SAVE_PATH):\n",
    "    os.makedirs(_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Build Graph\n",
    "relu = model(\"relu\")\n",
    "selu = model(\"selu\")\n",
    "#elu = model(\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Some Tensorflow configuration\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "# Initialize Dataset\n",
    "train_x, train_y = get_data_set(\"train\")\n",
    "test_x, test_y = get_data_set(\"test\")\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "    try:\n",
    "        print(\"Trying to restore last checkpoint ...\")\n",
    "        last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n",
    "        saver.restore(sess, save_path=last_chk_path)\n",
    "        print(\"Restored checkpoint from:\", last_chk_path)\n",
    "    except:\n",
    "        print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if _EPOCH != 0:\n",
    "        train_loss, train_accuracy, test_accuracy = train(\n",
    "            sess, _EPOCH, train_x, train_y, test_x, test_y, \n",
    "            models={\"relu\": relu, \"selu\": selu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Training Loss, Training Accuracy and Test Accuracy for the three activation functions\n",
    "plot(train_loss, train_accuracy, test_accuracy)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
